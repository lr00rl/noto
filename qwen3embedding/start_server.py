# start_server.py - å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬
import uvicorn
import logging
import sys
import os
import psutil
import torch
from pathlib import Path

def setup_memory_optimized_environment():
    """è®¾ç½®å†…å­˜ä¼˜åŒ–ç¯å¢ƒ"""
    # PyTorchå†…å­˜ä¼˜åŒ–
    os.environ.setdefault("PYTORCH_CUDA_ALLOC_CONF", "max_split_size_mb:128,garbage_collection_threshold:0.6")
    os.environ.setdefault("CUDA_LAUNCH_BLOCKING", "0")
    os.environ.setdefault("TORCH_CUDNN_BENCHMARK", "1")

    # Pythonå†…å­˜ä¼˜åŒ–
    os.environ.setdefault("PYTHONMALLOC", "malloc")
    os.environ.setdefault("MALLOC_TRIM_THRESHOLD_", "0")

    # ç¦ç”¨tokenizerå¹¶è¡ŒåŒ–ä»¥èŠ‚çœå†…å­˜
    os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")

    # å¦‚æœæ˜¯ä½å†…å­˜ç³»ç»Ÿï¼Œå¯ç”¨å†…å­˜æ˜ å°„
    memory_gb = psutil.virtual_memory().total / 1024**3
    if memory_gb < 16:
        os.environ.setdefault("TRANSFORMERS_OFFLINE", "1")
        os.environ.setdefault("HF_DATASETS_OFFLINE", "1")

def check_system_resources():
    """æ£€æŸ¥ç³»ç»Ÿèµ„æºå¹¶ç»™å‡ºå»ºè®®"""
    print("ğŸ” ç³»ç»Ÿèµ„æºæ£€æŸ¥:")

    # å†…å­˜æ£€æŸ¥
    memory = psutil.virtual_memory()
    memory_gb = memory.total / 1024**3
    print(f"   ç³»ç»Ÿå†…å­˜: {memory_gb:.1f}GB (å¯ç”¨: {memory.available / 1024**3:.1f}GB)")

    if memory_gb < 8:
        print("   âš ï¸  è­¦å‘Š: ç³»ç»Ÿå†…å­˜ä¸è¶³8GBï¼Œå»ºè®®å…³é—­å…¶ä»–ç¨‹åº")

    # GPUæ£€æŸ¥
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        print(f"   GPUæ•°é‡: {gpu_count}")

        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            gpu_memory_gb = props.total_memory / 1024**3
            print(f"   GPU {i}: {props.name} ({gpu_memory_gb:.1f}GB)")

            if gpu_memory_gb < 4:
                print(f"   âš ï¸  GPU {i} æ˜¾å­˜ä¸è¶³4GBï¼Œå°†ä½¿ç”¨CPU offload")
            elif gpu_memory_gb < 6:
                print(f"   âš ï¸  GPU {i} æ˜¾å­˜è¾ƒå°ï¼Œå»ºè®®ä½¿ç”¨0.6Bæ¨¡å‹")
    else:
        print("   âŒ æœªæ£€æµ‹åˆ°CUDA GPUï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")

    print()

def get_optimized_config():
    """æ ¹æ®ç³»ç»Ÿèµ„æºè·å–ä¼˜åŒ–é…ç½®"""
    config = {
        "host": "0.0.0.0",
        "port": 8000,
        "workers": 1,  # embeddingæœåŠ¡å¿…é¡»å•è¿›ç¨‹
        "loop": "asyncio",  # åœ¨ä½å†…å­˜ç³»ç»Ÿä½¿ç”¨asyncioè€Œä¸æ˜¯uvloop
        "http": "h11",     # ä½¿ç”¨æ›´è½»é‡çš„HTTPè§£æå™¨
        "log_level": "info",
        "access_log": True,
        "reload": False,
    }

    # æ ¹æ®å†…å­˜è°ƒæ•´é…ç½®
    memory_gb = psutil.virtual_memory().total / 1024**3

    if memory_gb >= 32:
        # é«˜å†…å­˜ç³»ç»Ÿ
        config.update({
            "loop": "uvloop",
            "http": "httptools",
            "limit_concurrency": 500,
            "limit_max_requests": 5000,
        })
        print("ğŸ“ˆ æ£€æµ‹åˆ°é«˜å†…å­˜ç³»ç»Ÿï¼Œä½¿ç”¨æ€§èƒ½ä¼˜åŒ–é…ç½®")

    elif memory_gb >= 16:
        # ä¸­ç­‰å†…å­˜ç³»ç»Ÿ
        config.update({
            "limit_concurrency": 200,
            "limit_max_requests": 2000,
        })
        print("ğŸ“Š æ£€æµ‹åˆ°ä¸­ç­‰å†…å­˜ç³»ç»Ÿï¼Œä½¿ç”¨å¹³è¡¡é…ç½®")

    else:
        # ä½å†…å­˜ç³»ç»Ÿ
        config.update({
            "limit_concurrency": 50,
            "limit_max_requests": 500,
            "timeout_keep_alive": 5,  # å‡å°‘ä¿æŒè¿æ¥æ—¶é—´
        })
        print("ğŸ”‹ æ£€æµ‹åˆ°ä½å†…å­˜ç³»ç»Ÿï¼Œä½¿ç”¨å†…å­˜ä¼˜åŒ–é…ç½®")

    # GPUç‰¹å®šé…ç½®
    if torch.cuda.is_available():
        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if gpu_memory_gb < 6:
            config["limit_concurrency"] = min(config.get("limit_concurrency", 50), 20)
            print(f"ğŸ¯ GPUæ˜¾å­˜è¾ƒå°({gpu_memory_gb:.1f}GB)ï¼Œé™åˆ¶å¹¶å‘æ•°ä¸º20")

    return config

def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    log_config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "default": {
                "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
            },
            "access": {
                "format": "%(asctime)s - %(client_addr)s - \"%(request_line)s\" %(status_code)s - %(process_time).3fs",
            },
        },
        "handlers": {
            "default": {
                "formatter": "default",
                "class": "logging.StreamHandler",
                "stream": "ext://sys.stdout",
            },
            "access": {
                "formatter": "access",
                "class": "logging.StreamHandler",
                "stream": "ext://sys.stdout",
            },
            "file": {
                "formatter": "default",
                "class": "logging.handlers.RotatingFileHandler",
                "filename": "embedding_server.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 3,
            },
        },
        "loggers": {
            "uvicorn": {"handlers": ["default", "file"], "level": "INFO", "propagate": False},
            "uvicorn.error": {"level": "INFO"},
            "uvicorn.access": {"handlers": ["access"], "level": "INFO", "propagate": False},
            "embedding_server": {"handlers": ["default", "file"], "level": "INFO"},
        },
    }
    return log_config

def main():
    """ä¸»å¯åŠ¨å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å†…å­˜ä¼˜åŒ–ç‰ˆ Qwen3 Embedding æœåŠ¡å™¨")
    print("=" * 50)

    # è®¾ç½®ç¯å¢ƒ
    setup_memory_optimized_environment()

    # æ£€æŸ¥ç³»ç»Ÿèµ„æº
    check_system_resources()

    # è·å–ä¼˜åŒ–é…ç½®
    config = get_optimized_config()

    # è®¾ç½®æ—¥å¿—
    log_config = setup_logging()

    print("ğŸ› ï¸  æœåŠ¡å™¨é…ç½®:")
    for key, value in config.items():
        if key not in ["log_config"]:
            print(f"   {key}: {value}")
    print()

    print("ğŸŒ æœåŠ¡åœ°å€:")
    print(f"   API: http://{config['host']}:{config['port']}")
    print(f"   æ–‡æ¡£: http://{config['host']}:{config['port']}/docs")
    print(f"   å¥åº·æ£€æŸ¥: http://{config['host']}:{config['port']}/health")
    print(f"   å†…å­˜ç»Ÿè®¡: http://{config['host']}:{config['port']}/memory/stats")
    print()

    try:
        # å¯åŠ¨æœåŠ¡å™¨
        uvicorn.run(
            "embedding_server:app",
            **config,
            log_config=log_config
        )
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æœåŠ¡å™¨å·²åœæ­¢")
    except Exception as e:
        print(f"\nâŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
